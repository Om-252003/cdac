{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWK_s_kpsHcK"
      },
      "source": [
        "---\n",
        "\n",
        "<center><h1>  Creating Dataframes  </h1></center>\n",
        "\n",
        "---\n",
        "\n",
        "In this notebook, we will learn how, to create dataframes, we can create a dataframes using the following methods.\n",
        "\n",
        " - Using an RDD\n",
        " - Using Collections\n",
        " - Using a CSV File\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#### `Importing the Required Libraies`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "X0-1_nn3sRcj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iSpxJ3q8sHcL"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Rk6RzLNLsHcM",
        "outputId": "7b6184d7-8cac-4a0e-9f14-c9c98b473ab3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e4077a24b60>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://5602d5bcfb56:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "spark = SparkSession.builder.getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFLQSkzjsHcM"
      },
      "source": [
        "----\n",
        "---\n",
        "\n",
        "#### `Spark DataFrame from an RDD`\n",
        "\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "R7zHPQYGsHcN"
      },
      "outputs": [],
      "source": [
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lo1V5iMVsHcN"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "students_data_rdd = sc.textFile('/content/module_8_students_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "FVwqzpOlsHcN",
        "outputId": "651f85e2-5fe2-407d-923d-86e97a2f28d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.RDD</b><br/>def __init__(jrdd: &#x27;JavaObject&#x27;, ctx: &#x27;SparkContext&#x27;, jrdd_deserializer: Serializer=AutoBatchedSerializer(CPickleSerializer()))</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/rdd.py</a>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
              "Represents an immutable, partitioned collection of elements that can be\n",
              "operated on in parallel.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 336);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Check the data type\n",
        "type(students_data_rdd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD6AskpesHcO",
        "outputId": "a09b324c-5792-480a-cbb7-3147e25fe1af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['101,A,Rohit,Gurgaon,65,77,43,66,87',\n",
              " '102,B,Akansha,Delhi,55,46,24,66,77',\n",
              " '103,A,Himanshu,Faridabad,75,38,84,38,58',\n",
              " '104,A,Ekta,Delhi,85,84,39,58,85',\n",
              " '105,B,Deepanshu,Gurgaon,34,55,56,23,66',\n",
              " '106,B,Ayush,Delhi,66,62,98,74,87',\n",
              " '107,B,Aditi,Delhi,76,83,75,38,58',\n",
              " '108,A,Sahil,Faridabad,55,32,43,56,66',\n",
              " '109,A,Krati,Delhi,34,53,25,67,75']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "students_data_rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4iG-UQmmsHcO"
      },
      "outputs": [],
      "source": [
        "students_data_rdd = students_data_rdd.map(lambda x: x.split(','))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj_OawDjsHcO",
        "outputId": "c5238a19-155a-4373-b534-679a39635133"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['101', 'A', 'Rohit', 'Gurgaon', '65', '77', '43', '66', '87'],\n",
              " ['102', 'B', 'Akansha', 'Delhi', '55', '46', '24', '66', '77'],\n",
              " ['103', 'A', 'Himanshu', 'Faridabad', '75', '38', '84', '38', '58'],\n",
              " ['104', 'A', 'Ekta', 'Delhi', '85', '84', '39', '58', '85'],\n",
              " ['105', 'B', 'Deepanshu', 'Gurgaon', '34', '55', '56', '23', '66'],\n",
              " ['106', 'B', 'Ayush', 'Delhi', '66', '62', '98', '74', '87'],\n",
              " ['107', 'B', 'Aditi', 'Delhi', '76', '83', '75', '38', '58'],\n",
              " ['108', 'A', 'Sahil', 'Faridabad', '55', '32', '43', '56', '66'],\n",
              " ['109', 'A', 'Krati', 'Delhi', '34', '53', '25', '67', '75']]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "students_data_rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oNQCAvDYsHcP"
      },
      "outputs": [],
      "source": [
        "# Create dataframe from rdd\n",
        "students_data_dataframe = students_data_rdd.toDF([\"roll_no\",\n",
        "                                                  \"section\",\n",
        "                                                  \"name\",\n",
        "                                                  \"city\",\n",
        "                                                  \"subject1\",\n",
        "                                                  \"subject2\",\n",
        "                                                  \"subject3\",\n",
        "                                                  \"subject4\",\n",
        "                                                  \"subject5\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnCM_D58sHcP",
        "outputId": "ce281115-17fb-4af5-d1be-08a1e6d21d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+---------+---------+--------+--------+--------+--------+--------+\n",
            "|roll_no|section|     name|     city|subject1|subject2|subject3|subject4|subject5|\n",
            "+-------+-------+---------+---------+--------+--------+--------+--------+--------+\n",
            "|    101|      A|    Rohit|  Gurgaon|      65|      77|      43|      66|      87|\n",
            "|    102|      B|  Akansha|    Delhi|      55|      46|      24|      66|      77|\n",
            "|    103|      A| Himanshu|Faridabad|      75|      38|      84|      38|      58|\n",
            "|    104|      A|     Ekta|    Delhi|      85|      84|      39|      58|      85|\n",
            "|    105|      B|Deepanshu|  Gurgaon|      34|      55|      56|      23|      66|\n",
            "|    106|      B|    Ayush|    Delhi|      66|      62|      98|      74|      87|\n",
            "|    107|      B|    Aditi|    Delhi|      76|      83|      75|      38|      58|\n",
            "|    108|      A|    Sahil|Faridabad|      55|      32|      43|      56|      66|\n",
            "|    109|      A|    Krati|    Delhi|      34|      53|      25|      67|      75|\n",
            "+-------+-------+---------+---------+--------+--------+--------+--------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display dataframe\n",
        "students_data_dataframe.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z4CWOIgsHcP"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "#### `Spark DataFrame from Collections`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "65dFLopQsHcP"
      },
      "outputs": [],
      "source": [
        "# Collection\n",
        "sample_data = [\n",
        "    (101, \"A\", \"Rohit\",    \"Gurugram\"),\n",
        "    (102, \"B\", \"Akansha\",  \"Delhi\"),\n",
        "    (103, \"A\", \"Himanshu\", \"Faridabad\"),\n",
        "    (104, \"A\", \"Ekta\",     \"Delhi\"),\n",
        "    (105, \"B\", \"Ayush\",    \"Delhi\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kSPVKTCrsHcQ"
      },
      "outputs": [],
      "source": [
        "# Create dataframe from collection\n",
        "dataframe_from_collections = spark.createDataFrame(data=sample_data,schema=[\"roll_no\",\n",
        "                                                                            \"section\",\n",
        "                                                                            \"name\",\n",
        "                                                                            \"city\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mju4SasRsHcQ",
        "outputId": "82d3f075-7259-497f-c429-c13d0646e742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+--------+---------+\n",
            "|roll_no|section|    name|     city|\n",
            "+-------+-------+--------+---------+\n",
            "|    101|      A|   Rohit| Gurugram|\n",
            "|    102|      B| Akansha|    Delhi|\n",
            "|    103|      A|Himanshu|Faridabad|\n",
            "|    104|      A|    Ekta|    Delhi|\n",
            "|    105|      B|   Ayush|    Delhi|\n",
            "+-------+-------+--------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display dataframe\n",
        "dataframe_from_collections.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqWFuuVKsHcQ"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "#### `Spark DataFrame from CSV file`\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1gZBJuwSsHcQ"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pyspark.sql.types as tp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "h3pETjwdsHcQ"
      },
      "outputs": [],
      "source": [
        "# Define schema or dataframe\n",
        "my_schema = tp.StructType([\n",
        "    tp.StructField(name= \"roll_no\", dataType= tp.IntegerType()),\n",
        "    tp.StructField(name= \"section\", dataType= tp.StringType()),\n",
        "    tp.StructField(name= \"name\",    dataType= tp.StringType()),\n",
        "    tp.StructField(name= \"city\",    dataType= tp.StringType()),\n",
        "    tp.StructField(name= \"subject1\",dataType= tp.IntegerType()),\n",
        "    tp.StructField(name= \"subject2\",dataType= tp.IntegerType()),\n",
        "    tp.StructField(name= \"subject3\",dataType= tp.IntegerType()),\n",
        "    tp.StructField(name= \"subject4\",dataType= tp.IntegerType()),\n",
        "    tp.StructField(name= \"subject5\",dataType= tp.IntegerType()),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "uX5VXiLqsHcQ"
      },
      "outputs": [],
      "source": [
        "# Create dataframe\n",
        "df_csv_schema = spark.read.csv(\"/content/module_8_students_data.csv\",\n",
        "                                             header=False,\n",
        "                                             schema=my_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "1a_KuVWQsHcQ",
        "outputId": "0b4b2756-86f8-4ad0-d780-b3ae88a3342e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Check type\n",
        "type(df_csv_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3SYbuwksHcQ",
        "outputId": "d60d564f-dc34-404f-9741-44dc3046f98d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+---------+---------+--------+--------+--------+--------+--------+\n",
            "|roll_no|section|     name|     city|subject1|subject2|subject3|subject4|subject5|\n",
            "+-------+-------+---------+---------+--------+--------+--------+--------+--------+\n",
            "|    101|      A|    Rohit|  Gurgaon|      65|      77|      43|      66|      87|\n",
            "|    102|      B|  Akansha|    Delhi|      55|      46|      24|      66|      77|\n",
            "|    103|      A| Himanshu|Faridabad|      75|      38|      84|      38|      58|\n",
            "|    104|      A|     Ekta|    Delhi|      85|      84|      39|      58|      85|\n",
            "|    105|      B|Deepanshu|  Gurgaon|      34|      55|      56|      23|      66|\n",
            "|    106|      B|    Ayush|    Delhi|      66|      62|      98|      74|      87|\n",
            "|    107|      B|    Aditi|    Delhi|      76|      83|      75|      38|      58|\n",
            "|    108|      A|    Sahil|Faridabad|      55|      32|      43|      56|      66|\n",
            "|    109|      A|    Krati|    Delhi|      34|      53|      25|      67|      75|\n",
            "+-------+-------+---------+---------+--------+--------+--------+--------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display dataframe\n",
        "df_csv_schema.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX1HX9TpsHcR"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "#### `Spark DataFrame from CSV file - with inferSchema`\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "edj0UFCGsHcR"
      },
      "outputs": [],
      "source": [
        "# Create dataframe with inferSchema\n",
        "df_csv_infer = spark.read.csv(\"/content/module_8_students_data.csv\",\n",
        "                                             header=False,\n",
        "                                             inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "XRm-bqrPsHcR",
        "outputId": "8b12227c-db97-47ce-dd22-0aba03bea12d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Check type\n",
        "type(df_csv_infer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owfXVWjlsHcR",
        "outputId": "27fe327f-d784-45d9-d446-769f29204cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+---------+---------+---+---+---+---+---+\n",
            "|_c0|_c1|      _c2|      _c3|_c4|_c5|_c6|_c7|_c8|\n",
            "+---+---+---------+---------+---+---+---+---+---+\n",
            "|101|  A|    Rohit|  Gurgaon| 65| 77| 43| 66| 87|\n",
            "|102|  B|  Akansha|    Delhi| 55| 46| 24| 66| 77|\n",
            "|103|  A| Himanshu|Faridabad| 75| 38| 84| 38| 58|\n",
            "|104|  A|     Ekta|    Delhi| 85| 84| 39| 58| 85|\n",
            "|105|  B|Deepanshu|  Gurgaon| 34| 55| 56| 23| 66|\n",
            "|106|  B|    Ayush|    Delhi| 66| 62| 98| 74| 87|\n",
            "|107|  B|    Aditi|    Delhi| 76| 83| 75| 38| 58|\n",
            "|108|  A|    Sahil|Faridabad| 55| 32| 43| 56| 66|\n",
            "|109|  A|    Krati|    Delhi| 34| 53| 25| 67| 75|\n",
            "+---+---+---------+---------+---+---+---+---+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display dataframe\n",
        "df_csv_infer.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50YYIg3rsHcR"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "#### `Rename DataFrame columns`\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "xbwBL3sRsHcR"
      },
      "outputs": [],
      "source": [
        "# Rename columns method 1\n",
        "df_csv_infer2 = df_csv_infer.withColumnRenamed(\"_c0\",\"roll_no\")\\\n",
        "                            .withColumnRenamed(\"_c1\",\"section\")\\\n",
        "                            .withColumnRenamed(\"_c2\",\"name\")\\\n",
        "                            .withColumnRenamed(\"_c3\",\"city\")\\\n",
        "                            .withColumnRenamed(\"_c4\",\"section_1\")\\\n",
        "                            .withColumnRenamed(\"_c5\",\"section_2\")\\\n",
        "                            .withColumnRenamed(\"_c6\",\"section_3\")\\\n",
        "                            .withColumnRenamed(\"_c7\",\"section_4\")\\\n",
        "                            .withColumnRenamed(\"_c8\",\"section_5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF7oIq3AsHcR",
        "outputId": "775b324f-add1-45d5-c86a-bf509c35724f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+---------+---------+---------+---------+---------+---------+---------+\n",
            "|roll_no|section|     name|     city|section_1|section_2|section_3|section_4|section_5|\n",
            "+-------+-------+---------+---------+---------+---------+---------+---------+---------+\n",
            "|    101|      A|    Rohit|  Gurgaon|       65|       77|       43|       66|       87|\n",
            "|    102|      B|  Akansha|    Delhi|       55|       46|       24|       66|       77|\n",
            "|    103|      A| Himanshu|Faridabad|       75|       38|       84|       38|       58|\n",
            "|    104|      A|     Ekta|    Delhi|       85|       84|       39|       58|       85|\n",
            "|    105|      B|Deepanshu|  Gurgaon|       34|       55|       56|       23|       66|\n",
            "|    106|      B|    Ayush|    Delhi|       66|       62|       98|       74|       87|\n",
            "|    107|      B|    Aditi|    Delhi|       76|       83|       75|       38|       58|\n",
            "|    108|      A|    Sahil|Faridabad|       55|       32|       43|       56|       66|\n",
            "|    109|      A|    Krati|    Delhi|       34|       53|       25|       67|       75|\n",
            "+-------+-------+---------+---------+---------+---------+---------+---------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display datframe\n",
        "df_csv_infer2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "vLYjuBaesHcR"
      },
      "outputs": [],
      "source": [
        "# Rename columns method 2\n",
        "column_names = [\"roll_no\",\"section\",\"name\",\"city\",\"section_1\",\"section_2\",\"section_3\",\"section_4\",\"section_5\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "rHYVDE0EsHcS"
      },
      "outputs": [],
      "source": [
        "# Rename columns\n",
        "df_csv_infer3 = df_csv_infer.toDF(*column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7Bze3CrsHcS",
        "outputId": "73b6b76e-631c-45cc-cd09-5f8ca515606f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+---------+---------+---------+---------+---------+---------+---------+\n",
            "|roll_no|section|     name|     city|section_1|section_2|section_3|section_4|section_5|\n",
            "+-------+-------+---------+---------+---------+---------+---------+---------+---------+\n",
            "|    101|      A|    Rohit|  Gurgaon|       65|       77|       43|       66|       87|\n",
            "|    102|      B|  Akansha|    Delhi|       55|       46|       24|       66|       77|\n",
            "|    103|      A| Himanshu|Faridabad|       75|       38|       84|       38|       58|\n",
            "|    104|      A|     Ekta|    Delhi|       85|       84|       39|       58|       85|\n",
            "|    105|      B|Deepanshu|  Gurgaon|       34|       55|       56|       23|       66|\n",
            "|    106|      B|    Ayush|    Delhi|       66|       62|       98|       74|       87|\n",
            "|    107|      B|    Aditi|    Delhi|       76|       83|       75|       38|       58|\n",
            "|    108|      A|    Sahil|Faridabad|       55|       32|       43|       56|       66|\n",
            "|    109|      A|    Krati|    Delhi|       34|       53|       25|       67|       75|\n",
            "+-------+-------+---------+---------+---------+---------+---------+---------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display dataframe\n",
        "df_csv_infer3.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdUwGWLysHcS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Pyspark 2",
      "language": "python",
      "name": "pyspark2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}